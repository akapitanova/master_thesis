{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-02T15:13:11.338387Z",
     "start_time": "2024-12-02T15:13:11.330741Z"
    }
   },
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from modules import UNet_conditional\n",
    "from diffusion import *\n",
    "from utils import *\n",
    "from torch.amp import autocast"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T15:13:12.862915Z",
     "start_time": "2024-12-02T15:13:12.725741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = \"models/test/ema_ckpt.pt\"\n",
    "print(\"Loading \", path)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "model = UNet_conditional(length=1024,\n",
    "                         feat_num=3, \n",
    "                         device=device).to(device)\n",
    "ckpt = torch.load(path, map_location=device)\n",
    "model.load_state_dict(ckpt)\n",
    "sampler = SpacedDiffusion(beta_start=1e-4, \n",
    "                          beta_end=0.02, \n",
    "                          noise_steps=1000, \n",
    "                          section_counts=[40], \n",
    "                          length=1024, \n",
    "                          device=device, \n",
    "                          rescale_timesteps=False)    \n",
    "    "
   ],
   "id": "d03120506696f7f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  models/test/ema_ckpt.pt\n",
      "Using device: cpu\n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T15:13:13.294696Z",
     "start_time": "2024-12-02T15:13:13.286217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict(model, sampler, test_dl, device, n_samples=4):\n",
    "    \"\"\"\n",
    "    Return predictions\n",
    "    \"\"\"\n",
    "    x_real = []\n",
    "    predictions = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(tqdm(test_dl, desc=\"Testing loop\")):\n",
    "        #for i, data in enumerate(test_dl):\n",
    "            vectors = data['data'].to(device)\n",
    "            settings = data['settings'].to(device)\n",
    "            \n",
    "            #with autocast(device_type=device, dtype=torch.float16):\n",
    "            pred = sampler.ddim_sample_loop(model=model, \n",
    "                         y=settings, \n",
    "                         cfg_scale=1, \n",
    "                         device=device, \n",
    "                         eta=1, \n",
    "                         n=n_samples\n",
    "                         )\n",
    "            \n",
    "            # we move predictions to cpu, in case they are stored on GPU\n",
    "            x_real.extend(vectors.cpu().tolist())\n",
    "            predictions.extend(pred.cpu().tolist())\n",
    "                \n",
    "    return x_real, predictions\n",
    "    "
   ],
   "id": "8479e01a27013828",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T15:13:33.629614Z",
     "start_time": "2024-12-02T15:13:14.343596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(model, sampler, device, test_csv_path, n_samples=4, batch_size = 4):\n",
    "    \"\"\"\n",
    "    Evaluate predictions\n",
    "    \"\"\"\n",
    "    # Load the test dataset\n",
    "    x_test, y_test = get_data(test_csv_path)\n",
    "    \n",
    "    test_dataset = CustomDataset(x_test, y_test)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    x_real, predictions = predict(model, sampler, test_dataloader, device=device, n_samples=n_samples)\n",
    "    mse = nn.MSELoss()\n",
    "    mse_errors = []\n",
    "    \n",
    "    for i, pred in enumerate(predictions):\n",
    "        err = mse(pred, x_real[i])\n",
    "        mse_errors.append(err)\n",
    "        \n",
    "    return mse_errors\n",
    "    \n",
    "mse_errors = evaluate(model, sampler, device, \"../data/test_data.csv\")"
   ],
   "id": "6a9aceac7254e477",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing loop:   0%|          | 0/392 [00:00<?, ?it/s]\n",
      "ddim sample loop:   0%|          | 0/40 [00:00<?, ?it/s]\u001B[A\n",
      "ddim sample loop:   2%|▎         | 1/40 [00:00<00:13,  2.94it/s]\u001B[A\n",
      "ddim sample loop:   5%|▌         | 2/40 [00:00<00:14,  2.67it/s]\u001B[A\n",
      "ddim sample loop:   8%|▊         | 3/40 [00:01<00:14,  2.62it/s]\u001B[A\n",
      "ddim sample loop:  10%|█         | 4/40 [00:01<00:12,  2.82it/s]\u001B[A\n",
      "ddim sample loop:  12%|█▎        | 5/40 [00:01<00:11,  2.95it/s]\u001B[A\n",
      "ddim sample loop:  15%|█▌        | 6/40 [00:02<00:11,  3.03it/s]\u001B[A\n",
      "ddim sample loop:  18%|█▊        | 7/40 [00:02<00:10,  3.10it/s]\u001B[A\n",
      "ddim sample loop:  20%|██        | 8/40 [00:02<00:10,  3.16it/s]\u001B[A\n",
      "ddim sample loop:  22%|██▎       | 9/40 [00:02<00:09,  3.16it/s]\u001B[A\n",
      "ddim sample loop:  25%|██▌       | 10/40 [00:03<00:09,  3.12it/s]\u001B[A\n",
      "ddim sample loop:  28%|██▊       | 11/40 [00:03<00:09,  3.16it/s]\u001B[A\n",
      "ddim sample loop:  30%|███       | 12/40 [00:03<00:08,  3.20it/s]\u001B[A\n",
      "ddim sample loop:  32%|███▎      | 13/40 [00:04<00:08,  3.24it/s]\u001B[A\n",
      "ddim sample loop:  35%|███▌      | 14/40 [00:04<00:08,  3.22it/s]\u001B[A\n",
      "ddim sample loop:  38%|███▊      | 15/40 [00:04<00:07,  3.28it/s]\u001B[A\n",
      "ddim sample loop:  40%|████      | 16/40 [00:05<00:07,  3.21it/s]\u001B[A\n",
      "ddim sample loop:  42%|████▎     | 17/40 [00:05<00:07,  3.24it/s]\u001B[A\n",
      "ddim sample loop:  45%|████▌     | 18/40 [00:05<00:06,  3.28it/s]\u001B[A\n",
      "ddim sample loop:  48%|████▊     | 19/40 [00:06<00:06,  3.28it/s]\u001B[A\n",
      "ddim sample loop:  50%|█████     | 20/40 [00:06<00:06,  3.25it/s]\u001B[A\n",
      "ddim sample loop:  52%|█████▎    | 21/40 [00:06<00:05,  3.27it/s]\u001B[A\n",
      "ddim sample loop:  55%|█████▌    | 22/40 [00:06<00:05,  3.25it/s]\u001B[A\n",
      "ddim sample loop:  57%|█████▊    | 23/40 [00:07<00:05,  3.13it/s]\u001B[A\n",
      "ddim sample loop:  60%|██████    | 24/40 [00:07<00:05,  3.14it/s]\u001B[A\n",
      "ddim sample loop:  62%|██████▎   | 25/40 [00:07<00:04,  3.14it/s]\u001B[A\n",
      "ddim sample loop:  65%|██████▌   | 26/40 [00:08<00:04,  3.10it/s]\u001B[A\n",
      "ddim sample loop:  68%|██████▊   | 27/40 [00:08<00:04,  3.11it/s]\u001B[A\n",
      "ddim sample loop:  70%|███████   | 28/40 [00:08<00:04,  3.00it/s]\u001B[A\n",
      "ddim sample loop:  72%|███████▎  | 29/40 [00:09<00:03,  3.04it/s]\u001B[A\n",
      "ddim sample loop:  75%|███████▌  | 30/40 [00:09<00:03,  3.08it/s]\u001B[A\n",
      "ddim sample loop:  78%|███████▊  | 31/40 [00:09<00:02,  3.08it/s]\u001B[A\n",
      "ddim sample loop:  80%|████████  | 32/40 [00:10<00:02,  2.97it/s]\u001B[A\n",
      "ddim sample loop:  82%|████████▎ | 33/40 [00:10<00:02,  3.02it/s]\u001B[A\n",
      "ddim sample loop:  85%|████████▌ | 34/40 [00:10<00:01,  3.03it/s]\u001B[A\n",
      "ddim sample loop:  88%|████████▊ | 35/40 [00:11<00:01,  2.98it/s]\u001B[A\n",
      "ddim sample loop:  90%|█████████ | 36/40 [00:11<00:01,  3.03it/s]\u001B[A\n",
      "ddim sample loop:  92%|█████████▎| 37/40 [00:11<00:01,  2.96it/s]\u001B[A\n",
      "ddim sample loop:  95%|█████████▌| 38/40 [00:12<00:00,  3.02it/s]\u001B[A\n",
      "ddim sample loop:  98%|█████████▊| 39/40 [00:12<00:00,  3.00it/s]\u001B[A\n",
      "ddim sample loop: 100%|██████████| 40/40 [00:12<00:00,  3.09it/s]\u001B[A\n",
      "Testing loop:   0%|          | 1/392 [00:12<1:24:29, 12.97s/it]\n",
      "ddim sample loop:   0%|          | 0/40 [00:00<?, ?it/s]\u001B[A\n",
      "ddim sample loop:   2%|▎         | 1/40 [00:00<00:12,  3.13it/s]\u001B[A\n",
      "ddim sample loop:   5%|▌         | 2/40 [00:00<00:12,  3.00it/s]\u001B[A\n",
      "ddim sample loop:   8%|▊         | 3/40 [00:01<00:12,  2.96it/s]\u001B[A\n",
      "ddim sample loop:  10%|█         | 4/40 [00:01<00:12,  2.97it/s]\u001B[A\n",
      "ddim sample loop:  12%|█▎        | 5/40 [00:01<00:11,  2.95it/s]\u001B[A\n",
      "ddim sample loop:  15%|█▌        | 6/40 [00:02<00:12,  2.65it/s]\u001B[A\n",
      "Testing loop:   0%|          | 1/392 [00:15<1:39:17, 15.24s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 21\u001B[0m\n\u001B[1;32m     17\u001B[0m         mse_errors\u001B[38;5;241m.\u001B[39mappend(err)\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m mse_errors\n\u001B[0;32m---> 21\u001B[0m mse_errors \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../data/test_data.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[26], line 11\u001B[0m, in \u001B[0;36mevaluate\u001B[0;34m(model, device, test_csv_path, n_samples, batch_size)\u001B[0m\n\u001B[1;32m      8\u001B[0m test_dataset \u001B[38;5;241m=\u001B[39m CustomDataset(x_test, y_test)\n\u001B[1;32m      9\u001B[0m test_dataloader \u001B[38;5;241m=\u001B[39m DataLoader(test_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m---> 11\u001B[0m x_real, predictions \u001B[38;5;241m=\u001B[39m \u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_samples\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m mse \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mMSELoss()\n\u001B[1;32m     13\u001B[0m mse_errors \u001B[38;5;241m=\u001B[39m []\n",
      "Cell \u001B[0;32mIn[25], line 17\u001B[0m, in \u001B[0;36mpredict\u001B[0;34m(model, test_dl, device, n_samples)\u001B[0m\n\u001B[1;32m     14\u001B[0m settings \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msettings\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m#with autocast(device_type=device, dtype=torch.float16):\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m pred \u001B[38;5;241m=\u001B[39m \u001B[43msampler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mddim_sample_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m             \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msettings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m             \u001B[49m\u001B[43mcfg_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m             \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m             \u001B[49m\u001B[43meta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m             \u001B[49m\u001B[43mn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_samples\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m             \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# we move predictions to cpu, in case they are stored on GPU\u001B[39;00m\n\u001B[1;32m     26\u001B[0m x_real\u001B[38;5;241m.\u001B[39mextend(vectors\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mtolist())\n",
      "File \u001B[0;32m~/skola/DIPLOMKA/master_thesis/src/diffusion.py:182\u001B[0m, in \u001B[0;36mGaussianDiffusion.ddim_sample_loop\u001B[0;34m(self, model, y, cfg_scale, device, eta, n)\u001B[0m\n\u001B[1;32m    179\u001B[0m final \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    180\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m--> 182\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sample \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mddim_sample_loop_progressive(model,\n\u001B[1;32m    183\u001B[0m                                                 y,\n\u001B[1;32m    184\u001B[0m                                                 cfg_scale,\n\u001B[1;32m    185\u001B[0m                                                 device\u001B[38;5;241m=\u001B[39mdevice,\n\u001B[1;32m    186\u001B[0m                                                 eta\u001B[38;5;241m=\u001B[39meta,\n\u001B[1;32m    187\u001B[0m                                                 n\u001B[38;5;241m=\u001B[39mn):\n\u001B[1;32m    188\u001B[0m     final \u001B[38;5;241m=\u001B[39m sample\n\u001B[1;32m    191\u001B[0m \u001B[38;5;66;03m# normalization to back numbers, for intensities: lower_bound=0, upper_bound=3925\u001B[39;00m\n",
      "File \u001B[0;32m~/skola/DIPLOMKA/master_thesis/src/diffusion.py:221\u001B[0m, in \u001B[0;36mGaussianDiffusion.ddim_sample_loop_progressive\u001B[0;34m(self, model, y, cfg_scale, device, eta, n)\u001B[0m\n\u001B[1;32m    219\u001B[0m t \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([i] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(img), device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m    220\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 221\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mddim_sample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    222\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    224\u001B[0m \u001B[43m                           \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mcfg_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[43m                           \u001B[49m\u001B[43meta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meta\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    227\u001B[0m     out[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m t\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m out\n",
      "File \u001B[0;32m~/skola/DIPLOMKA/master_thesis/src/diffusion.py:241\u001B[0m, in \u001B[0;36mGaussianDiffusion.ddim_sample\u001B[0;34m(self, model, x, t, y, cfg_scale, eta)\u001B[0m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mddim_sample\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    232\u001B[0m                 model,\n\u001B[1;32m    233\u001B[0m                 x,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    236\u001B[0m                 cfg_scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n\u001B[1;32m    237\u001B[0m                 eta\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m):  \u001B[38;5;66;03m# TODO why is eta 0, isnt nonzero_mask * sigma * noise always 0 then?\u001B[39;00m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;124;03m    Sample x_{t-1} from the model using DDIM.\u001B[39;00m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 241\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mp_mean_variance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcfg_scale\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    243\u001B[0m     \u001B[38;5;66;03m# Usually our model outputs epsilon, but we re-derive it\u001B[39;00m\n\u001B[1;32m    244\u001B[0m     \u001B[38;5;66;03m# in case we used x_start or x_prev prediction.\u001B[39;00m\n\u001B[1;32m    245\u001B[0m     eps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_predict_eps_from_xstart(x, t, out[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpred_xstart\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "File \u001B[0;32m~/skola/DIPLOMKA/master_thesis/src/diffusion.py:424\u001B[0m, in \u001B[0;36mSpacedDiffusion.p_mean_variance\u001B[0;34m(self, model, *args, **kwargs)\u001B[0m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mp_mean_variance\u001B[39m(\u001B[38;5;28mself\u001B[39m, model, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):  \u001B[38;5;66;03m# pylint: disable=signature-differs\u001B[39;00m\n\u001B[1;32m    418\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    419\u001B[0m \u001B[38;5;124;03m    This method computes the mean and variance at each\u001B[39;00m\n\u001B[1;32m    420\u001B[0m \u001B[38;5;124;03m    timestep for the reverse diffusion process.\u001B[39;00m\n\u001B[1;32m    421\u001B[0m \u001B[38;5;124;03m    It’s overridden here to wrap the model correctly\u001B[39;00m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;124;03m    using self._wrap_model(model).\u001B[39;00m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mp_mean_variance\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wrap_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    425\u001B[0m \u001B[43m                                   \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/skola/DIPLOMKA/master_thesis/src/diffusion.py:287\u001B[0m, in \u001B[0;36mGaussianDiffusion.p_mean_variance\u001B[0;34m(self, model, x, t, y, cfg_scale, vartype)\u001B[0m\n\u001B[1;32m    285\u001B[0m model_output \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mforward(x, t, y)\n\u001B[1;32m    286\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cfg_scale \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 287\u001B[0m     uncond_model_output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    288\u001B[0m     model_output \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlerp(uncond_model_output,\n\u001B[1;32m    289\u001B[0m                               model_output,\n\u001B[1;32m    290\u001B[0m                               cfg_scale)\n\u001B[1;32m    291\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m vartype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfixed_large\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    292\u001B[0m     \u001B[38;5;66;03m# print(self.posterior_variance[1])\u001B[39;00m\n",
      "File \u001B[0;32m~/skola/DIPLOMKA/master_thesis/src/diffusion.py:464\u001B[0m, in \u001B[0;36m_WrappedModel.__call__\u001B[0;34m(self, x, t, y)\u001B[0m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, t, y):\n\u001B[0;32m--> 464\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/skola/DIPLOMKA/master_thesis/src/diffusion.py:461\u001B[0m, in \u001B[0;36m_WrappedModel.forward\u001B[0;34m(self, x, t, y)\u001B[0m\n\u001B[1;32m    458\u001B[0m         new_ts \u001B[38;5;241m=\u001B[39m new_ts\u001B[38;5;241m.\u001B[39mfloat() \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1000.0\u001B[39m \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moriginal_num_steps)\n\u001B[1;32m    459\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m new_ts\n\u001B[0;32m--> 461\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/mt_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/skola/DIPLOMKA/master_thesis/src/modules.py:273\u001B[0m, in \u001B[0;36mUNet_conditional.forward\u001B[0;34m(self, x, t, y)\u001B[0m\n\u001B[1;32m    270\u001B[0m x4 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbot2(x4)\n\u001B[1;32m    271\u001B[0m x4 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbot3(x4)\n\u001B[0;32m--> 273\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mup1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx4\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx3\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    274\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msa4(x)\n\u001B[1;32m    275\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mup2(x, x2, t)\n",
      "File \u001B[0;32m~/anaconda3/envs/mt_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/skola/DIPLOMKA/master_thesis/src/modules.py:163\u001B[0m, in \u001B[0;36mUp.forward\u001B[0;34m(self, x, skip_x, t)\u001B[0m\n\u001B[1;32m    161\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mup(x)\n\u001B[1;32m    162\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([skip_x, x], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m--> 163\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;66;03m# Embedding repeated along the new length dimension for 1D data\u001B[39;00m\n\u001B[1;32m    165\u001B[0m emb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39memb_layer(t)[:, :, \u001B[38;5;28;01mNone\u001B[39;00m]\u001B[38;5;241m.\u001B[39mrepeat(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n",
      "File \u001B[0;32m~/anaconda3/envs/mt_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/envs/mt_env/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 139\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/mt_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/skola/DIPLOMKA/master_thesis/src/modules.py:105\u001B[0m, in \u001B[0;36mDoubleConv.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m    104\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresidual:\n\u001B[0;32m--> 105\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mgelu(x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdouble_conv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    106\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    107\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdouble_conv(x)\n",
      "File \u001B[0;32m~/anaconda3/envs/mt_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/envs/mt_env/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 139\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/mt_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/envs/mt_env/lib/python3.8/site-packages/torch/nn/modules/conv.py:307\u001B[0m, in \u001B[0;36mConv1d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    306\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 307\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/mt_env/lib/python3.8/site-packages/torch/nn/modules/conv.py:303\u001B[0m, in \u001B[0;36mConv1d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    299\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    300\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv1d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    301\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    302\u001B[0m                     _single(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 303\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    304\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c9a8d789183a8b6b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
